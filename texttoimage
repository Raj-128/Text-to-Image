import io
import torch
import cv2
import numpy as np
import streamlit as st
from PIL import Image, ImageDraw, ImageFont
from diffusers import AutoPipelineForText2Image
from deep_translator import GoogleTranslator
import nest_asyncio
from pathlib import Path

# Environment Setup
nest_asyncio.apply()
device = "cuda" if torch.cuda.is_available() else "cpu"
dtype = torch.float16 if torch.cuda.is_available() else torch.float32

# UI Setup
st.set_page_config(page_title="ğŸ§  AI Image Generator", layout="centered")
st.markdown("""
    <style>
        .stApp { background: transparent; }
        video#bgvid {
            position: fixed;
            top: 0;
            left: 0;
            min-width: 100%;
            min-height: 100%;
            z-index: -1;
            object-fit: cover;
        }
        html, body, .stApp, h1, h2, h3, p, label, div, span {
            font-family: 'Poppins', sans-serif;
            color: black;
        }
        @media (prefers-color-scheme: dark) {
            html, body, .stApp, h1, h2, h3, p, label, div, span {
                font-family: 'Fira Code', monospace;
                color: white;
            }
        }
    </style>
    <link href="https://fonts.googleapis.com/css2?family=Fira+Code&family=Poppins&display=swap" rel="stylesheet">
    <video autoplay muted loop id="bgvid">
        <source src="https://videos.pexels.com/video-files/1943483/1943483-uhd_2560_1440_25fps.mp4" type="video/mp4">
    </video>
""", unsafe_allow_html=True)

st.markdown("<h1 style='text-align:center;'>ğŸ¨ Text-to-Image Generator</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;'>Type your imagination, apply filters, and download creative AI images!</p>", unsafe_allow_html=True)

# Session history
if "history" not in st.session_state:
    st.session_state["history"] = []

# Sidebar Controls
with st.sidebar:
    st.header("âš™ Generation Settings")
    steps = st.slider("ğŸŒ€ Inference Steps", 5, 30, 15)
    width = st.slider("ğŸ“ Width", 256, 1024, 512, step=64)
    height = st.slider("ğŸ“ Height", 256, 1024, 512, step=64)
    quality = st.slider("ğŸ“· JPG Quality", 10, 100, 95)

    st.header("ğŸ§ Filters & Effects")
    brightness = st.slider("â˜€ Brightness", 0.5, 2.0, 1.0)
    contrast = st.slider("ğŸ”² Contrast", 0.5, 2.0, 1.0)
    edge_detection = st.checkbox("ğŸ–Š Apply Edge Detection")
    sepia = st.checkbox("ğŸ“œ Apply Sepia Effect")

    st.header("ğŸ–Š Text Overlay")
    add_text = st.checkbox("Add Text Overlay?")
    if add_text:
        overlay_text = st.text_input("Enter Text", value="Generated by AI")

    st.header("ğŸŒ Translation")
    translate = st.checkbox("Translate Prompt?")
    if translate:
        dest_language = st.text_input("Target Language (e.g., 'en', 'fr')", value="en")

# Art style presets
styles = {
    "None": "",
    "Realistic": "photorealistic, ultra-HD, highly detailed",
    "Anime": "anime style, vibrant colors, cel shading",
    "Fantasy": "dreamlike, magical realism, glowing elements",
    "Pixel Art": "pixelated, 8-bit game style, retro colors"
}
style = st.selectbox("ğŸ¨ Select Art Style", list(styles.keys()))

# Load model (Stable Diffusion 1.5)
@st.cache_resource
def load_model():
    model_id = "runwayml/stable-diffusion-v1-5"

    try:
        pipe = AutoPipelineForText2Image.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            revision="fp16" if torch.cuda.is_available() else "main"
        ).to("cuda" if torch.cuda.is_available() else "cpu")

        pipe.enable_attention_slicing()
        return pipe

    except Exception as e:
        st.error(f"ğŸš¨ Error loading model '{model_id}': {e}")
        return None

# Apply filters
def apply_filters(image, brightness=1.0, contrast=1.0, edge_detection=False, sepia=False):
    image = np.array(image)
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    image = cv2.convertScaleAbs(image, alpha=brightness * contrast, beta=0)

    if sepia:
        sepia_kernel = np.array([[0.272, 0.534, 0.131],
                                 [0.349, 0.686, 0.168],
                                 [0.393, 0.769, 0.189]], dtype=np.float32)
        image = image.astype(np.float32) / 255.0
        image = cv2.transform(image, sepia_kernel)
        image = (image * 255).clip(0, 255).astype(np.uint8)

    if edge_detection:
        edges = cv2.Canny(image, 100, 200)
        image = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)

    return Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

# Add text overlay
def add_text_overlay(image, text, position=(50, 50), text_color=(255, 255, 255)):
    draw = ImageDraw.Draw(image)
    try:
        default_font_path = str(Path(cv2.__file__).parent / "qt" / "fonts" / "DejaVuSans.ttf")
        font = ImageFont.truetype(default_font_path, size=int(image.width * 0.05))
    except:
        font = ImageFont.load_default()
    shadow = (3, 3)
    draw.text((position[0] + shadow[0], position[1] + shadow[1]), text, font=font, fill=(0, 0, 0))
    draw.text(position, text, font=font, fill=text_color)
    return image

# Prompt input
prompt = st.text_input("ğŸ“ Enter your prompt", placeholder="e.g., a castle in the clouds with glowing lights")

pipeline = load_model()

# Generate image
if st.button("ğŸ¨ Generate Image") and prompt:
    try:
        if translate:
            prompt = GoogleTranslator(source="auto", target=dest_language).translate(prompt)

        if style != "None":
            prompt = f"{styles[style]}, {prompt}"

        with st.spinner("ğŸ§° Thinking... Generating your masterpiece..."):
            result = pipeline(
                prompt=prompt,
                height=height,
                width=width,
                num_inference_steps=steps
            )
            image = result.images[0]
            image = apply_filters(image, brightness, contrast, edge_detection, sepia)

            if add_text:
                image = add_text_overlay(image, overlay_text)

            st.session_state["history"].append({
                "prompt": prompt,
                "image": image.copy()
            })

            st.markdown(f"""
                <div style='text-align:center; margin-top:20px; padding:10px; background-color:#1f2937; color:white; border-radius:10px; font-size:18px;'>
                    <strong>Prompt Used:</strong> {prompt}
                </div>
            """, unsafe_allow_html=True)

            st.image(image, caption="ğŸ‰ Your Generated Image", use_container_width=True)

            filename = st.text_input("ğŸ“‚ File Name for Download", value="my_image")
            img_bytes = io.BytesIO()
            image.save(img_bytes, format="JPEG", quality=quality)
            img_bytes.seek(0)

            st.download_button("ğŸ“… Download Image", data=img_bytes, file_name=f"{filename}.jpg", mime="image/jpeg")
    except Exception as e:
        st.error(f"âŒ Error generating image: {str(e)}")

# Show History
if st.session_state["history"]:
    st.markdown("## ğŸ•˜ Image Generation History")
    for i, item in enumerate(reversed(st.session_state["history"][-5:]), 1):
        st.image(item["image"], use_container_width=True)
        img_bytes = io.BytesIO()
        item["image"].save(img_bytes, format="JPEG", quality=95)
        img_bytes.seek(0)
        st.download_button(
            label=f"ğŸ“¥ Download Image {i}",
            data=img_bytes,
            file_name=f"generated_image_{i}.jpg",
            mime="image/jpeg"
        )

